citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
citr:::insert_citation()
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
# Select subset of numerical variables for regression modelling
data_joinedT <- subset(data_joinedT, select = c(Type, `Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ Weekly_Sales, prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment, IsHoliday, data= data_joinedT)
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ Weekly_Sales, prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment + IsHoliday, data= data_joinedT)
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment + IsHoliday, data= data_joinedT)
summary(fit) #R2 = 96.7%
citr:::insert_citation()
citr:::insert_citation()
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
# Select a subset of variables for regression modelling
data_joinedT <- subset(data_joinedT, select = c(`Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
# Bivariate correlations
# cor(data_joinedT)
# scatterplot matrix
# scatterplotMatrix(data_joinedT, spread=FALSE, lty.smooth=2,
# main="Scatter Plot Matrix")
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment + IsHoliday, data= data_joinedT)
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
# Select a subset of variables for regression modelling
# data_joinedT <- subset(data_joinedT, select = c(`Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
# Bivariate correlations
# cor(data_joinedT)
# scatterplot matrix
# scatterplotMatrix(data_joinedT, spread=FALSE, lty.smooth=2,
# main="Scatter Plot Matrix")
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment + IsHoliday, data= data_joinedT)
summary(fit) #R2 = 96.73%
# Fit the model (1)
plot(data_joinedT$`Size (sq ft)`, data_joinedT$Weekly_Sales)
# Fit the model (1)
plot(data_joinedT$`Size (sq ft)`, data_joinedT$Weekly_Sales)
cor(data_joinedT$`Size (sq ft)`, data_joinedT$Weekly_Sales)
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
# Select a subset of variables for regression modelling
# data_joinedT <- subset(data_joinedT, select = c(`Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
# Bivariate correlations
# cor(data_joinedT)
# scatterplot matrix
# scatterplotMatrix(data_joinedT, spread=FALSE, lty.smooth=2,
# main="Scatter Plot Matrix")
# Scientific notation Off
options(scipen=999)
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment + IsHoliday, data= data_joinedT)
summary(fit) #R2 = 96.73%
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
# Scientific notation Off
options(scipen=999)
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey",
main=NULL, xlab="Weekly Sales", ylab="Frequency")
# Scientific notation On
options(scipen=001)
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`
<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
# Delete promotions
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
# Convert date info to date format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot correlation Weekely Sales ~ Previous Year Weekly Sales
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main=NULL,
xlab="Weekly Sales", ylab="Previous year Weekly Sales")
# Delete rowns with NA's
data_joined = na.omit(data_joined)
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week
# Because of week mismatches between years take average of previous years sales
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
# Glance at the first 6 rows of the model dataset
head(data_joined)
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
# Select a subset of variables for regression modelling
# data_joinedT <- subset(data_joinedT, select = c(`Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
# Bivariate correlations
# cor(data_joinedT)
# scatterplot matrix
# scatterplotMatrix(data_joinedT, spread=FALSE, lty.smooth=2,
# main="Scatter Plot Matrix")
# Scientific notation Off
options(scipen=999)
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + IsHoliday + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment, data= data_joinedT)
summary(fit) #R2 = 96.73%
coef(fit)
summary(fit) #R2 = 96.73%
# Fit the model (1)
fit <- lm(Weekly_Sales ~ + IsHoliday + Type + `Size (sq ft)`+ prev_Weekly_Sales + Temperature + Fuel_Price + CPI + Unemployment, data= data_joinedT)
coef(fit)
summary(fit) #R2 = 96.73%
install.packages("TeX")
