---
title: "Understanding Data and its Environment: Report assessment"
author: "Eugeni Vidal"
date: March 15, 2018
output:
  pdf_document:
    toc: true
    number_sections: true
bibliography: references.bib
---

<br>

# 1. Introduction

The cambridge Dictionary describes sales forecasting as "the statement of what the amount or value of a company's sales is likely to be in the future, based on information available now about the market, past sales, etc".

The increase of competition, complexity in business tasks, and the fact that nowadays circumstances, in general, tend to change more rapidly makes increasingly important and necessary for companies the use of forecasting technics for the prediction of their future prospects (Forecasting for sales p.1).

<Aim>
This report aims to describe, pre-process and analyse a set of data based on historical sales data collected from a nationwide retailer in the U.S as well as on external factors, so as to lead to the development of an accurate predictive model. 

<Method>
The methodology followed is divided into 7 different steps, from describing the data to building and assessing the model developed. Notice that although each step is taken in order, the whole process has to be understood as a set of nested loops rather than a straight line (see figure 1).

![](images/Methodology diagram.jpg)
<br>
<p align="center">*Figure 1. Methodology diagram*<p align="center"/>

The whole process has been done using the open software R and it is reproducible based on code available at https://github.com/eugenividal/Understanding-data-report.

This report is written as clearly and easily as possible, with the pretense that any person, without much prior knowledge in forecasting or in the R software, can understand it. For this purpose, the document describes not only the statistical process followed, but also the code used with the software R. 

<br>

# 2. Step 1. Describe the data

The first thing to start a project with the R software is to install the packages that we will need and load their libraries. To do this we use the code shown below. 

```{r,  message=FALSE, cache=FALSE}
# Activate libraries
library(tidyverse)
library(VIM)
library(dplyr)
library(psych)
library(lubridate)
library(caret)
library(car)
```

Secondly, we will load the data into the R environment.

```{r, message=FALSE, cache=FALSE}
# Load data
stores = read_csv("data/stores.csv")
features = read_csv("data/features.csv")
test = read_csv("data/test.csv")
train = read_csv("data/train.csv")
```

<br>

We are provided with 4 data sets (stores, features, train, and test). All of them with the same format: comma-separated values (csv). 

Below is a brief description of each of the datasets and their variables:

<Describe the type of each variable (categorical, numeric, etc)?>

**stores.csv (45 obs. of 3 variables)**

- Store: the anonymised store number <numeric> 
- Type: tore type, A: supercentre, B: superstore, C: supermarket <character>
- Size: store size (in square feet) <numeric>

**features.csv (8,190 obs. of 12 variables)**

- Store: the anonymised store number <numeric>
- Date:	the week with the dated Friday <character>
- Temperature: average temperature in the region <numeric>
- Fuel_Price: cost of fuel in the region <numeric>
- Promotions:	anonymised data related to promotions, mainly price reductions that the retailer is running <numeric>
- CPI: the consumer price index <numeric>
- Unemployment: the unemployment rate <numeric>
- IsHoliday: whether the week is a special holiday week <boolean>

**train.csv (421,570 obs. of 5 variables)**

- Store: the anonymised store number <numeric>
- Department: the anonymised department number <numeric>
- Date: the week with the dated Friday <character>
- Weekly_Sales: sales for the given department in the given store <numeric>
- IsHoliday: whether the week is a special holiday week <boolean>

**test.csv (115,069 obs. of 5 variables)**

The validation dataset has the same fields as the train.csv, except we need to predict the weekly sales for each triplet of store, department, and date from 02/11/2012 to 26/07/2013.

<br>

Variables of each dataset have been explored through counts, summary statistics, crosstabulation and visualisations in order to identify potential inconsistences or problems in the data.

The main problems detected are briefly described below.

<"What is or isn’t a problem varies with the data mining technique used in this case multiple regression, so we have focus here and in the section of fixing problem on those aspects that could affect somehow the multiregression analysis" (Berry, 2004, p.72)>. 

**1. Inconsistent data encoding**. In the stores dataset, some stores might be wrongly classified. Two stores under 50,000 sq ft are coded as type B and other two as type A, when presumably small size stores (<50000 sq ft) should be type C. 

```{r, include=FALSE, cache=FALSE}
# Crosstab Size and Type store data set
crosstab_Size_Type <- table(stores$Type, stores$`Size (sq ft)`)
# Print first 10 rows of mydata
head(crosstab_Size_Type, n=10)
```

**2. Missing values**. In the features dataset, 24,040 values are missing, almost 50% in the promotion variables and 7% in the `CPI` and `Unemployment` ones. With the function of the VIM package aggr() we can visualise them for each variable alone and for each combination of variables.

```{r figs, echo=FALSE, fig.width=7,fig.height=6,fig.cap="\\label{fig:figs}plotting example"}
# Plot missing values
aggr(features, prop=FALSE, col = "grey", cex.lab = 0.85, cex.axis = 0.65, cex.main = 0.85)
```
<br>
<p align="center">*Figure 2. Missing values*<p align="center"/>
<br>

There are not missing values in the ret of the datasets.

**3. Negative values**. Some of the values in the promotions variables are negative: 4 in `Promotion1`, 25 in `Promotion2`, 13 in `Promotion3`, and 2 in `Promotion5`. Also within the `Weekly Sales` (1286 of 421571 (0.3%)) variable in the train dataset.

**4. Class type errors**. The  class of the `Date` variable within the train, features and test datasets is character instead of date. This doesn't allow to sort the data properly. Also in terms of class, it would be useful to have the variable IsHoliday in numeric type (1 or 0) instead of boolean (true or false). 

**5. Data not normally distributed**. Finally, to mentione that the data in some variables is not normallly distributed. The following histogram of ‘Weekly Sales‘, created with the generic function hist (), is clear example of that. 

```{r,include=FALSE, cache=FALSE}
# Scientific notation Off
options(scipen=999)
```

```{r}
# Plot a histogram
hist(train$Weekly_Sales, cex.lab = 0.85, cex.axis = 0.85, cex.main = 0.85, col = "grey", main="Histogram Weekly Sales", xlab="Weekly Sales", ylab="Frequency")
```
<p align="center">*Figure 3. Histogram Weekly Sales*<p align="center"/>

<br>

<Extreme values?. Here, in fixing problems or fiting the model?>

```{r,include=FALSE, cache=FALSE}
# Scientific notation On
options(scipen=001)
```

<br>

# 3. Step 2. Join the model data set

The next step is to join the stores, train and features datasets in a single one. This will allow us to make the analysis simpler and more straightforward. 

The test dataset will be left aside to gauge the effectiveness of the models once build.

To performance the join, we apply a left join. We chose this type of join because we want to end up having the same number of rows as the train dataset which contains the variable we want to predict `Weekly Sales`.  

First, we link the stores dataset with the train one, using the common attribute `Store`; then the resultant dataset with the features dataset, using the common attributes `Store`, `Date` and `IsHoliday`. See the code below.

```{r}
# Join store-level data onto training dataset (so we know size and type)
data_joined = left_join(train, y= stores)
# Join train_joined onto features dataset (so we know the rest of variables)
data_joined = left_join(data_joined, y= features)
```

The result is a data frame that contains 421,570 observations of 16 variables. Notice that 1,755 observations don't match between train and features. This is because we did a left join and the features datasets collect data until 2013-07-26 while the train dataset only until 2013-07-26. This way, we leave behind 1,755 observations and the 585 NA's previously detected in `CPI`, `Unemployment` and `IsHoliday`.

<br>

# 4. Step 3. Cleaning and fixing problems with the data

In this section, we will fix inconsistencies or potential problems identified in the section data description. 

<"What is or isn’t a problem varies with the data mining technique used"" (Berry, 2004, p.72)>. 

## 4.1. Resolving inconsistent data encoding

We will assume that the type of store is based on size and consequently, will recode all stores under 50000 sq ft as C type. This way we solve the potential inconsistency of 4 stores under 5000 sq ft coded as type A and B.

```{r}
# Recode `stores$Type` based on `stores$Size (sq ft)`
data_joined$Type[(data_joined$`Size (sq ft)`<50000)] <- "C"
data_joined$Type[(data_joined$`Size (sq ft)`>=50000) & (data_joined$`Size (sq ft)`<150000)] <- "B"
data_joined$Type[(data_joined$`Size (sq ft)`>=150000)] <- "A"
```

## 4.2. Dealing with missing values

There are several approaches when we find missing data: delete the cases containing missing data, or replace (impute) the missing values with reasonable alternative data values (R in action, p.353)

Deciding how to treat missing values will depend on your estimation of which procedures will produce the most reliable and accurate results (R in action, p.354). 

There are many methods for dealing with missing data

In this case, given that promotion variables have almost 50% of their values missing (N.A) and that the correlation between these variable and the Weekly Sales is low (see graph), we will not consider and remove them from the training dataset.

```{r}
# Delete promotions because 50% data are missing
data_joined$Promotion1 <- NULL
data_joined$Promotion2 <- NULL
data_joined$Promotion3 <- NULL
data_joined$Promotion4 <- NULL
data_joined$Promotion5 <- NULL
```

The missing value in are not a rpoblem anymore because when we joined the NAs disaper.

## 4.3. Dealing with negative values

After analyzing the data we have concluded that the negative values identified in `Weekly Sales` are returned products from previous weeks. So, no changes will be done in this sense. 

## 4.4. Class type conversion

We will change the class type of `IsHoliday` variable into numeric using the general function `as.numeric()`.

```{r}
# Convert IsHoliday to numeric
data_joined$IsHoliday <- as.numeric(data_joined$IsHoliday)
```

To convert the date information into date we will use the package `lubridate` and the function `mdy ()`.

```{r message=FALSE}
# Convert date info in format 'dmy'
data_joined$Date <- dmy(data_joined$Date)
```

## 4.5. Normalization of data distribution

We can see that the Weekly Sales and other variables are not normally distributed. However, we won't consider that linear transformations (such as standardization) of our data will affect the statistical relationships among our variables, and therefore we will keep them the way they are now (check for literature). This will be checked once the model is decided.

<br>

# 5. Step 4. Transform the data

Once the inconsistencies or potential problems are fixed, we will make some transformations in order to prepare the dataset for building the predictive model.

First we will create a week number of year in order to compare them.

```{r}
# Create a week number of the year variable
data_joined$WeekNum <- as.numeric(format(data_joined$Date+3,"%U"))
```

```{r}
# Create a year variable
data_joined$year = lubridate::year(data_joined$Date)
```

Second, we will create a variable of previous years. A good predictor of this years sales is the previous year's sales (The Complete Guide to Accelerating Sales Force Performance). 

Sales of the given year are highly correlated with sales of the previous year. As we can see in the graph.

```{r}
# Create a previous year sales variable
prevyear = select(data_joined, year, WeekNum, Dept, Store, prev_Weekly_Sales = Weekly_Sales)
prevyear$year = prevyear$year + 1
summary(prevyear$year)
# Create variable Sales previous year
data_joined = left_join(data_joined, prevyear)
# Plot data joined
plot(data_joined$Weekly_Sales, data_joined$prev_Weekly_Sales,col = "grey", main="Correlation Weekly Sales", xlab="Weekly Sales", ylab="Previous year Weekly Sales")
```
<br>
<p align="center">*Figure 4. Correlation Weekly Sales ~ Weekly Sales*<p align="center"/>
<br>

Due to the fact that the new variable is based on `Weekly_Sales` of the previous year, there will be one year of missing values. 

We will handle with this applying listwise deletion, in other words, delating all observations with missing data for further analysis. This will reduce the sample size by 38% (261541/421570) and consequently could reduce statistical power. However, an approach that employs the entire dataset (including cases with missing data) could bias the results of the subsequent analysis (Bennett, 2001, p.464).

```{r}
# clean rowns with na's
data_joined = na.omit(data_joined)
```

The next step is to line-up holidays from one year and the other.

```{r}
# Match holiday weeks to holiday weeks. Adjust for Easter and adjust for the different Christmas week 

```

```{r}
# Take logical average for missing data 

```

```{r}
# Because of week mismatches between years take average of previous years sales 

```

Create a variable Sales/size?

Finally, we will reorder all the variables the way we feel better and we will have a glance of the

```{r, include=FALSE, cache=FALSE}
# Reorganise the columns
data_joined <- data_joined[c(2,1,6,7,3,4,14,8,9,10,11,12,5)]
```

At this point, using the `head()` function we can have a glimpse of how the traning dataset looks like.

```{r}
# Glance at the first 6 rows of the model dataset
head(data_joined)
```

<br>

# 6. Step 5. Data partition

In this section, the model set is divided into two parts. The first one, the training set (dataT), will be used to build the model; and the second one, the validation set (dataV), to adjust it. 

<The test set that we put aside before, will be used to gauge the effectiveness of the models when applied to unseen data>. 

<why 80%? (reference needed)>

For the partition, we will use the `caret` package.

```{r message=FALSE}
#subset the data into train and test
n = nrow(data_joined)
trainIndex = sample(1:n, size = round(0.8*n), replace=FALSE)
data_joinedT = data_joined[trainIndex ,]
data_joinedV = data_joined[-trainIndex ,]
```

<br>

# 7. Step 6. Choose the model

The choice of forecasting technique or model to use is a major consideration. There is a multiplicity of different methods to apply, from pure guesswork to highly mathematical statistical analysis [forecasting for sales].

The choice is always a compromise between accuracy, time-scale and cost. To make sure that the best use is made of the available information, the assumptions used in formulating the forecast must be clearly understood by both the forecaster and the decision-maker who uses the forecast [Forecasting for sales].

In this particualr case we will have use a multiple regression approach for the following reasons:

- Multiregression is more understandable for non-specialist with a knowledge of forecasting. Multi regression is a techique that is simpler, easier to understand and also more accessible to people with no background in maths and forecasting.

- Rather than use a complex relationship between the forecast variable and an independent variable (which has also to be guessed), it is simpler, and quite probably more accurate, merely to guess the forecast. It will usually be cheaper and quicker as well.

Multiple regression analysis is a multivariate statistical technique for examining the linear correlations between two or more independent variables and a single dependent variable.

# 8. Step 7. Build the model

## 8.1 Initial model

Multiple regression model uses the following formula:

Weekly_Sales = B0 + B1 x Type + B2 x Size + B3 x prev_Weekly_Sales...

In the initial model we will consider all candidate variables and will be built using the training sample of the data.

The first think is to select the candidate variables, a subset of variables for the regression.

```{r}
# Select a subset of variables for regression modelling
data_joinedT <- subset(data_joinedT, select = c(Type, `Size (sq ft)`, Weekly_Sales, prev_Weekly_Sales, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday))
```

All the candidate variables are numercial except Type and IsHoliday which are categorical: values that describe a 'quality' or 'characteristic' of a data unit (reference). Categorical variables with two levels can be directly entered as predictor or predicted variables in a multiple regression model. However, categorical variables with more than two levels like Type, have to be transformed. In this case r converts the three level of the Type variable in two dichotomous variables: Type B and Type C.

Now let's run the initial model.

```{r}
# Fit the model (1)
fit <- lm(Weekly_Sales ~., data= data_joinedT)
summary(fit) #R2 = 96.7%
```

## 8.2 Fit the model

We will perform additional tests on the trainig data and will use a stepwise selection of variables by backwards elimination.

First we will check for multi-collinearity with Variance Inflation Factor.

```{r}
# Plot a correlation plot
#pairs.panels(data_joinedT, col="red")
```

Correlated: none VIF=1, moderately 1<VIF<5, ** highly 5<VIF<10, ...

```{r}
# Variance Inflation Factor
vif(fit)
```

Whit this test we realise that the level of Vif of `Type` is high. 

`Type` and `Size` variable give very similar information (pressumably, size is based on type), although `Size` is much more precise and numerial. Consequeltly, We will drop the `Type` variable.

```{r}
# Refit the model (2) - drop IsHoliday, Temperature, Fuel Price, CPI and Unemployment
fit <- lm(Weekly_Sales ~. - Type, data= data_joinedT)
summary(fit) #R2 = 96.69%
```

```{r}
# Variance Inflation Factor
vif(fit)
```

VIF, F-ratio and p-values say it is good, so no need to do anything else.

The bext is to check the Monoscedasticity among them (even distribution of residuals)

Finally the p-value of coefficients and R2?F statistic of the model.

## 8.3 Final model

The final model takes as predictors: Prev_Weekly_Sales, Size and .

```{r}
# Refit the model (2) - drop IsHoliday, Temperature, Fuel Price, CPI and Unemployment
fit <- lm(Weekly_Sales ~ prev_Weekly_Sales + `Size (sq ft)`, data= data_joinedT)
summary(fit) #R2 = 96.67%
```

Observe that R-squared almost did not change and all Ps are good.

```{r}
# Refit the model (3) - Size
fit <- lm(Weekly_Sales ~ prev_Weekly_Sales, data= data_joinedT)
summary(fit) #R2 = 96.67%
```

Observe that R-squared almost did not change and all Ps are good.

<br>

# 9. Step 8. Assess the model

Finally, to check the model to know if this is a good or not a good model we will use the validation sample of the data.


```{r}
#     Find all predicted values for both a training set and a validation set
data_joinedT$Pred.Weekly_Sales <- predict(fit, 
    newdata = subset(data_joinedT, select=c(prev_Weekly_Sales, `Size (sq ft)`)))
data_joinedV$Pred.Weekly_Sales <- predict(fit, 
    newdata = subset(data_joinedV, select=c(prev_Weekly_Sales, `Size (sq ft)`)))
```

```{r}
# The theoretical model performance is defined here as R-Squared
summary(fit)
```

```{r}

# Check how good is the model on the training set - correlation^2, RME and MAE
train.corr <- round(cor(data_joinedT$Pred.Weekly_Sales, data_joinedT$Weekly_Sales), 2)
train.RMSE <- round(sqrt(mean((data_joinedT$Pred.Weekly_Sales -  data_joinedT$Weekly_Sales)^2)))
train.MAE <- round(mean(abs(data_joinedT$Pred.Weekly_Sales - data_joinedT$Weekly_Sales)))
c(train.corr^2, train.RMSE, train.MAE)
```

```{r}
# Check how good is the model on the validation set - correlation^2, RME and MAE
valid.corr <- round(cor(data_joinedV$Pred.Weekly_Sales, data_joinedV$Weekly_Sales), 2)
valid.RMSE <- round(sqrt(mean((data_joinedV$Pred.Weekly_Sales - data_joinedV$Weekly_Sales)^2)))
valid.MAE <- round(mean(abs(data_joinedV$Pred.Weekly_Sales - data_joinedV$Weekly_Sales)))
c(valid.corr^2, valid.RMSE, valid.MAE)
```

<br>

# 10. Conclusions

This report develops an accurate model for the prediction os sales for a nationwide retailer in the U.S. 

<summary of all the steps followed>
After 7 different steps, from describing the data to building and assessing the model developed, the conclusion and interpretations of it are the following:

<conclusive points>

- From all the information that we had available, the best predictor of is the sales from the prior year. it has the most predictive power
- The second better was the size of the store.
- The influence of external factors is minimal. 

Sales vary over time (for some reason not explained by the other predictors), and that this variation is smooth - so one days sales are not too different from the day before or the day after.

This model essentially says that in the absence of other information, sales should be the same as they were yesterday. 

The most challenging aspects have been the creation of the prior year sales, to line up important weeks - for example predict thanksgiving by thanksgiving regardless of which week of the year it is.

<Las statement>
With this model the organisation is able to plan bussness in future. Probably more accurate model could have been done, but the strong point of this one is that is simpler and more understandable for non very matemathical people.