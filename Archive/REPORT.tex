\documentclass[11pt,]{article}
\usepackage[]{mathpazo}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Understanding Data and its Environment: Report assessment},
            pdfkeywords={pandoc, r markdown, knitr},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apsr}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Understanding Data and its Environment: Report assessment}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{true}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{March 15, 2018}


\begin{document}
\maketitle

\section{1. Introduction}\label{introduction}

Forecasting or making predictions of sales is one of the most important
and challenging issues for retailers around the
world\citep{reference_needed}.

This report explains the approach taken to forecast sales for a
nationwide retailer in the U.S based on historical sales data for the
departments of 45 stores.

The consideration of the effects of promotional activities is an
additional difficulty in the analysis given the fact that part of the
promotion related data is absent from historical records.

The whole process using R is described in the following sections below.

The report is reproducible based on code available at
\url{https://github.com/eugenividal/Understanding-data-report}.

\section{2. Data description}\label{data-description}

The first stage before describing the data is to load it into the R
environment. To to that, we will use the \texttt{tidyverse} package and
load it with the \texttt{library()}function:

install.packages(``tidyverse'')

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'tibble' was built under R version 3.4.3
\end{verbatim}

\begin{verbatim}
## Warning: package 'tidyr' was built under R version 3.4.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# load data}
\KeywordTok{source}\NormalTok{(}\StringTok{"code/load-data.R"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can check that these files have been loaded with the following
command:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ls}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "features" "stores"   "test"     "train"
\end{verbatim}

We are provided with 4 data sets all in comma-separated values (csv)
format: stores (45 obs. of 3 variables), features (8,190 obs. of 12
variables), train (421,570 obs. of 5 variables) and test (115,069 obs.
of 5 variables). Each of the data sets and its features are explained
below. Describe the type of each variable (categorial, numeric,
etc\ldots{})

\begin{itemize}
\tightlist
\item
  \textbf{stores.csv}
\end{itemize}

\begin{quote}
\begin{itemize}
\tightlist
\item
  Store: the anonymised store number
\item
  Type: store type, A: supercentre, B: superstore, C: supermarket
\item
  Size : store size (in square feet)
\end{itemize}
\end{quote}

\begin{itemize}
\tightlist
\item
  \textbf{features.csv}
\end{itemize}

\begin{quote}
\begin{itemize}
\tightlist
\item
  Store: the anonymised store number
\item
  Date: the week with the dated Friday
\item
  Temperature: average temperature in the region
\item
  Fuel\_Price: cost of fuel in the region
\item
  Promotions: anonymised data related to promotions, mainly price
  reductions that the retailer is running. Promotion data is only
  available after Nov. 2011, and is not available for all stores all the
  time. Any missing value is marked with an NA.
\item
  CPI: the consumer price index
\item
  Unemployment: the unemployment rate
\item
  IsHoliday: whether the week is a special holiday week
\end{itemize}
\end{quote}

\begin{itemize}
\tightlist
\item
  \textbf{train.csv}
\end{itemize}

\begin{quote}
\begin{itemize}
\tightlist
\item
  Store: the anonymised store number
\item
  Department: the anonymised department number
\item
  Date: the week with the dated Friday
\item
  Weekly\_Sales: sales for the given department in the given store
\item
  IsHoliday: whether the week is a special holiday week
\end{itemize}
\end{quote}

\begin{itemize}
\tightlist
\item
  \textbf{test.csv}
\end{itemize}

The validation dataset have the same fields as the train.csv, except we
need to predict the weekly sales for each triplet of store, department,
and date from 02/11/2012 to 26/07/2013.

\subsection{2.1 Quality}\label{quality}

\subsubsection{Completeness}\label{completeness}

Promotion data is only available after November 2011 and is not
available for all stores all the time, missing values are marked with an
N/A. For promotion 1, 4157 of the 8191 values are marked with N/A, for
promotion 2, 5269, for promotion 3, 4576 and for promotion 4, 4725 and
for promotion 5 4139. Such a high volume of missing data could
potentially have an impact on prediction if it is not dealt with in an
appropriate way.

\subsubsection{Accuracy}\label{accuracy}

There are some negative values within the data we have been given that
we should be aware of. Within the features data set there are negative
values for the temperature records and within the train data set there
is 1286 negative values out of the 421571 data entries for the weekly
sales figures.

\subsubsection{Consistency}\label{consistency}

The dates within the train, features and test datasets are all given in
an English date format, despite them being from an American company. It
is important to ensure that variables are formatted in the same way in
each data set.

The variable IsHoliday is given as a true or false statement which may
be difficult to process further in to the analysis, so can potentially
be changed to a binary.

\subsection{2.2 Relevance}\label{relevance}

At this stage of the process we are assuming that all variables will be
relevant until the modelling process begins (see section 4). It is
expected that variables such as the store size and type will have a
constant effect, whereas temperature and the price of petrol may have
more subtle implications and may only be seasonal fluctuations.

\section{3. Data preparation}\label{data-preparation}

In this step we will carry out some ``techniques'' to arrange the data
in a way that makes the analysis easier and to produce a better model.

\subsection{3.1. Joining}\label{joining}

First of all, we will join the three data sets (stores, train and
features). This will allow us to make the analysis simpler and more
straightforward. The data will be linked using the attributes in common.
Store, to link stores with train dataset; and Store, Date and IsHoliday
to link the first dataset joined and features dataset.

To performance the join we will use \texttt{dplyr} package and the type
of join will be left (using the function \texttt{left\_join\ ()}). In
other words, we will merge the three datasets in one matching all the
rows from the train dataset with the rest of the datasets.

No missing or duplicate key values were detected.

In conclusion, the data linkage process will not present great
difficulties due to the fact that: there are common attributes to join
the tables, all the tables have the same format (csv), and no missing or
duplicate key values were found.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\CommentTok{# join store-level data onto training dataset (so we know size and type)}
\NormalTok{train_joined =}\StringTok{ }\KeywordTok{left_join}\NormalTok{(train, }\DataTypeTok{y=} \NormalTok{stores)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "Store"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Join train_joined onto features dataset (so we know the ret of variables)}
\NormalTok{train_joined =}\StringTok{ }\KeywordTok{left_join}\NormalTok{(train_joined, }\DataTypeTok{y=} \NormalTok{features)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = c("Store", "Date", "IsHoliday")
\end{verbatim}

The result is a data frame with all the features that contains 421,570
observations. IF we had done a full\_joine there would have been 1,755
obsertacions that don't match between train and features. Why? the date
is different - guess.

\subsection{3.2. Cleaning}\label{cleaning}

\subsubsection{Missing values}\label{missing-values}

Use Pandas' interpolate function to estimate - or could not use these
sections to train models (Chris).

Check how many NA values we have.

To know how many NA we have we can us the following code.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Count number of TRUEs}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(train_joined))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1422431
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Find mising values}
\KeywordTok{summary}\NormalTok{(train_joined)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Store           Dept           Date            Weekly_Sales   
##  Min.   : 1.0   Min.   : 1.00   Length:421570      Min.   : -4989  
##  1st Qu.:11.0   1st Qu.:18.00   Class :character   1st Qu.:  2080  
##  Median :22.0   Median :37.00   Mode  :character   Median :  7612  
##  Mean   :22.2   Mean   :44.26                      Mean   : 15981  
##  3rd Qu.:33.0   3rd Qu.:74.00                      3rd Qu.: 20206  
##  Max.   :45.0   Max.   :99.00                      Max.   :693099  
##                                                                    
##  IsHoliday           Type            Size (sq ft)     Temperature    
##  Mode :logical   Length:421570      Min.   : 34875   Min.   : -2.06  
##  FALSE:391909    Class :character   1st Qu.: 93638   1st Qu.: 46.68  
##  TRUE :29661     Mode  :character   Median :140167   Median : 62.09  
##                                     Mean   :136728   Mean   : 60.09  
##                                     3rd Qu.:202505   3rd Qu.: 74.28  
##                                     Max.   :219622   Max.   :100.14  
##                                                                      
##    Fuel_Price      Promotion1         Promotion2         Promotion3       
##  Min.   :2.472   Min.   :    0.27   Min.   :  -265.8   Min.   :   -29.10  
##  1st Qu.:2.933   1st Qu.: 2240.27   1st Qu.:    41.6   1st Qu.:     5.08  
##  Median :3.452   Median : 5347.45   Median :   192.0   Median :    24.60  
##  Mean   :3.361   Mean   : 7246.42   Mean   :  3334.6   Mean   :  1439.42  
##  3rd Qu.:3.738   3rd Qu.: 9210.90   3rd Qu.:  1926.9   3rd Qu.:   103.99  
##  Max.   :4.468   Max.   :88646.76   Max.   :104519.5   Max.   :141630.61  
##                  NA's   :270889     NA's   :310322     NA's   :284479     
##    Promotion4         Promotion5            CPI         Unemployment   
##  Min.   :    0.22   Min.   :   135.2   Min.   :126.1   Min.   : 3.879  
##  1st Qu.:  504.22   1st Qu.:  1878.4   1st Qu.:132.0   1st Qu.: 6.891  
##  Median : 1481.31   Median :  3359.4   Median :182.3   Median : 7.866  
##  Mean   : 3383.17   Mean   :  4629.0   Mean   :171.2   Mean   : 7.960  
##  3rd Qu.: 3595.04   3rd Qu.:  5563.8   3rd Qu.:212.4   3rd Qu.: 8.572  
##  Max.   :67474.85   Max.   :108519.3   Max.   :227.2   Max.   :14.313  
##  NA's   :286603     NA's   :270138
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fins index of missing values in Weekly_Sales column}
\KeywordTok{which}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(train_joined$Weekly_Sales))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## integer(0)
\end{verbatim}

Besides missing values, we want to know if there are values in the data
that are too extreme or bizarre to be plausible.

\subsection{3.3. Transformation}\label{transformation}

\subsubsection{Type conversion}\label{type-conversion}

str(train\_joined\$IsHoliday)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# convert IsHoliday to numeric}
\NormalTok{train_joined$IsHoliday <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(train_joined$IsHoliday)}
\end{Highlighting}
\end{Shaded}

class(train\_joined\$IsHoliday)

class(train\$Date)

TO conver the infomration into dmy we will use the packe
\texttt{lubridate}.

str(train\_joined\$Date)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'lubridate' was built under R version 3.4.3
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'lubridate'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:base':
## 
##     date
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# convert date info in format 'dmy'}
\NormalTok{train_joined$Date <-}\StringTok{ }\KeywordTok{dmy}\NormalTok{(train_joined$Date)}
\end{Highlighting}
\end{Shaded}

class(train\_joined\$Date)

The class change is done, but I couldn't change to the English format
``\%Y-\%m-\%d'' to ``\%d/\%m/\%Y''.

\subsubsection{Generating variables}\label{generating-variables}

We generate new columns: 1) Include a Week Number of the year (code
needed); 2) Add a return column.

class(train\$Date)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Week number of the year}
\NormalTok{train_joined$WeekNum <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{format}\NormalTok{(train_joined$Date}\DecValTok{+3}\NormalTok{,}\StringTok{"%U"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

I would like to have WeekNum at the beginning of rhe table. How can I
reorder columns in a table?

\subsection{3.4 Data reduction}\label{data-reduction}

Finally, we will reduce the data set? Shold we reduce the data set? It
depends on the model we are going to use I guess. After performing this
procedure we have x observations which makes our data more manageable
for further analysis.

And this is the way the data set frame looks once pre-processed (show
the data in case we reduce it).

\subsection{3.5 Subseting the data}\label{subseting-the-data}

``We will partition the training set into two different data frames in
order to keep our analysis consistent and avoid testing on our training
data''

To do this we will use \texttt{caret} package.

install.packages(``caret'') library(caret)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Subset the data into train and test}
\NormalTok{n =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(train_joined)}
\NormalTok{trainIndex =}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\NormalTok{:n, }\DataTypeTok{size =} \KeywordTok{round}\NormalTok{(}\FloatTok{0.8}\NormalTok{*n), }\DataTypeTok{replace=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{train_joined.train =}\StringTok{ }\NormalTok{train_joined[trainIndex ,]}
\NormalTok{train_joined.validation =}\StringTok{ }\NormalTok{train_joined[-trainIndex ,]}
\end{Highlighting}
\end{Shaded}

\section{4. Exploratory analysis}\label{exploratory-analysis}

``Once the data has been input and clean up, the next step is to explore
each of the variables one at a time. This will provide us with
inforamtion about the distribution of each varible, which is helpful in
understanding the characteristics of the sample, identifying unexpected
or problematic avalues, and selecting appropiate statistical methods''.
NExt a subset of variables is typically studied two at a time. This step
can help to uncover basic relationships among variables, and is a useful
first step in developing more complex models``.

``For a small glimpse of how the data looks like we can refer to the
following picture''.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(train_joined.train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 17
##   Store  Dept Date       Weekly_Sales IsHoliday Type  `Size (sq ft)`
##   <int> <int> <date>            <dbl>     <dbl> <chr>          <int>
## 1     4    97 2011-12-30      30151.         1. A             205863
## 2    30     2 2010-10-22      13151.         0. C              42988
## 3     6    26 2011-03-11       9697.         0. A             202505
## 4    36    60 2011-11-04        114.         0. A              39910
## 5    16    54 2011-05-20         25.9        0. B              57197
## 6    38    10 2012-08-24        361.         0. C              39690
## # ... with 10 more variables: Temperature <dbl>, Fuel_Price <dbl>,
## #   Promotion1 <dbl>, Promotion2 <dbl>, Promotion3 <dbl>,
## #   Promotion4 <dbl>, Promotion5 <dbl>, CPI <dbl>, Unemployment <dbl>,
## #   WeekNum <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{aggregate}\NormalTok{(train_joined.train[,}\StringTok{"Weekly_Sales"}\NormalTok{], }\DataTypeTok{by=}\NormalTok{train_joined.train[,}\KeywordTok{c}\NormalTok{(}\StringTok{"Store"}\NormalTok{), }\DataTypeTok{drop=}\OtherTok{FALSE}\NormalTok{], mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Store Weekly_Sales
## 1      1    21602.588
## 2      2    27388.674
## 3      3     6309.743
## 4      4    28790.664
## 5      5     4981.883
## 6      6    21890.593
## 7      7     8415.105
## 8      8    13245.940
## 9      9     8773.906
## 10    10    26299.782
## 11    11    19290.030
## 12    12    14628.485
## 13    13    27211.477
## 14    14    28890.291
## 15    15     9022.744
## 16    16     7848.298
## 17    17    13036.587
## 18    18    15857.039
## 19    19    20379.690
## 20    20    29510.259
## 21    21    11411.390
## 22    22    15079.614
## 23    23    19758.609
## 24    24    18894.149
## 25    25    10370.605
## 26    26    14425.023
## 27    27    24938.340
## 28    28    18641.191
## 29    29     8145.646
## 30    30     8786.008
## 31    31    19834.456
## 32    32    16309.030
## 33    33     5744.155
## 34    34    13435.351
## 35    35    13772.535
## 36    36     8626.582
## 37    37    10099.282
## 38    38     7467.422
## 39    39    21286.267
## 40    40    13755.386
## 41    41    18022.318
## 42    42    11324.038
## 43    43    13441.665
## 44    44     6003.184
## 45    45    11653.399
\end{verbatim}

Graphs data visualization with \texttt{ggplot} package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\CommentTok{# Plot sales per each of the department}
\KeywordTok{ggplot}\NormalTok{(train_joined,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=} \NormalTok{Date, }\DataTypeTok{y=} \NormalTok{Weekly_Sales)) +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Dept))+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Sales per store department"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sales"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"Department"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{REPORT_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot sales per type of store}
\KeywordTok{ggplot}\NormalTok{(train_joined,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=} \NormalTok{Date, }\DataTypeTok{y=} \NormalTok{Weekly_Sales)) +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Type))+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"Sales per store department"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sales"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"Type of store"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{REPORT_files/figure-latex/unnamed-chunk-12-1.pdf}

Graphs to see the correlation between the different variables

There are many packages and approach for forecasting. We could use the
\texttt{lm()} function to do a linear regression, for example. Here we
use the xgboost package.

class(test\$Date)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot weekly sales vs CPI}
\KeywordTok{ggplot}\NormalTok{(train_joined,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=} \NormalTok{CPI, }\DataTypeTok{y=} \NormalTok{Weekly_Sales)) +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{Type)) +}\KeywordTok{stat_summary}\NormalTok{(}\DataTypeTok{fun.data=}\NormalTok{mean_cl_normal) +}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{'lm'}\NormalTok{) +}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"weekly sales vs CPI"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Sales"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"Type of store"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Computation failed in `stat_summary()`:
## Hmisc package required for this function
\end{verbatim}

\includegraphics{REPORT_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot weekly sales vs Unemployment}
\KeywordTok{ggplot}\NormalTok{(train_joined,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=} \NormalTok{Unemployment, }\DataTypeTok{y=} \NormalTok{Weekly_Sales)) +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{train_joined$Type))+}\KeywordTok{stat_summary}\NormalTok{(}\DataTypeTok{fun.data=}\NormalTok{mean_cl_normal) +}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method=}\StringTok{'lm'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Computation failed in `stat_summary()`:
## Hmisc package required for this function
\end{verbatim}

\includegraphics{REPORT_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot weekly sales vs Temperature}
\KeywordTok{ggplot}\NormalTok{(train_joined,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=} \NormalTok{Temperature, }\DataTypeTok{y=} \NormalTok{Weekly_Sales)) +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color=}\NormalTok{train_joined$Type)) +}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'gam'
\end{verbatim}

\includegraphics{REPORT_files/figure-latex/unnamed-chunk-15-1.pdf}

There is no clear correlation between the varibles previously graphed.
BUt there is correlation between\ldots{}

Correlation matrix between all of our numerical features?

\section{5. Creating predictive
models}\label{creating-predictive-models}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1 =}\StringTok{ }\KeywordTok{lm}\NormalTok{(Weekly_Sales ~}\StringTok{ }\NormalTok{Dept +}\StringTok{ }\NormalTok{Store +}\StringTok{ }\NormalTok{Type +}\StringTok{ }\NormalTok{Promotion1 +}\StringTok{ }\NormalTok{Promotion2 +}\StringTok{ }\NormalTok{Promotion3 +}\StringTok{ }\NormalTok{Promotion4 +}\StringTok{ }\NormalTok{Promotion5 +}\StringTok{ }\NormalTok{CPI +}\StringTok{ }\NormalTok{Unemployment, }\DataTypeTok{data =} \NormalTok{train_joined)}
\KeywordTok{summary} \NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = Weekly_Sales ~ Dept + Store + Type + Promotion1 + 
##     Promotion2 + Promotion3 + Promotion4 + Promotion5 + CPI + 
##     Unemployment, data = train_joined)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -41046 -14496  -7194   6190 593823 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.715e+04  6.143e+02  44.205  < 2e-16 ***
## Dept          1.097e+02  2.555e+00  42.945  < 2e-16 ***
## Store        -1.490e+02  6.753e+00 -22.064  < 2e-16 ***
## TypeB        -8.599e+03  1.636e+02 -52.575  < 2e-16 ***
## TypeC        -7.740e+03  8.340e+02  -9.281  < 2e-16 ***
## Promotion1    7.507e-02  1.513e-02   4.961 7.01e-07 ***
## Promotion2    2.446e-02  7.686e-03   3.183  0.00146 ** 
## Promotion3    1.406e-01  7.101e-03  19.803  < 2e-16 ***
## Promotion4   -2.093e-02  1.928e-02  -1.086  0.27763    
## Promotion5    1.355e-01  1.212e-02  11.180  < 2e-16 ***
## CPI          -3.629e+01  2.080e+00 -17.447  < 2e-16 ***
## Unemployment -3.997e+02  4.828e+01  -8.277  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 23970 on 97044 degrees of freedom
##   (324514 observations deleted due to missingness)
## Multiple R-squared:  0.06112,    Adjusted R-squared:  0.06102 
## F-statistic: 574.3 on 11 and 97044 DF,  p-value: < 2.2e-16
\end{verbatim}

Linear model to find a specific value for Weekly Sales that we want to
predict?

\section{6. Evaluation of forecasting
accuracy}\label{evaluation-of-forecasting-accuracy}

table(features\$Date)

\section{7. Conclusions}\label{conclusions}

You should, in the conclusions, report on the limitations of the data
you have used or what future studies of the same topic might need to
look for.

\renewcommand\refname{References}
\bibliography{My library.bib}


\end{document}
